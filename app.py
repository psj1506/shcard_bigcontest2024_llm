import os
import numpy as np
import pandas as pd
from transformers import AutoTokenizer, AutoModel
import torch
import faiss
import streamlit as st
import google.generativeai as genai
import logging
import re

# ê²½ë¡œ ì„¤ì •
data_path = './data'
module_path = './modules'

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(filename='chatbot_logs.log', level=logging.INFO, 
                    format='%(asctime)s:%(levelname)s:%(message)s')

# Gemini ëª¨ë¸ ì„¤ì •
GOOGLE_API_KEY = st.secrets["API_KEY"]
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv(os.path.join(data_path, "JEJU_DATA.csv"), encoding='cp949')
df_tour = pd.read_csv(os.path.join(data_path, "JEJU_TOUR.csv"), encoding='cp949')
text_tour = df_tour['text'].tolist()

# ìµœì‹ ì—°ì›” ë°ì´í„°ë§Œ ì‚¬ìš©
df = df.loc[df.groupby('ê°€ë§¹ì ëª…')['ê¸°ì¤€ì—°ì›”'].idxmax()].reset_index(drop=True)

# 'text' ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
if 'text' not in df.columns:
    st.error("ë°ì´í„°ì…‹ì— 'text' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ í•¨ìˆ˜ ì •ì˜ (í•¨ìˆ˜ëŠ” í˜¸ì¶œ ì „ì— ì •ì˜ë˜ì–´ì•¼ í•¨)
def load_faiss_index(index_path=os.path.join(module_path, 'faiss_index_1.index')):
    if os.path.exists(index_path):
        try:
            index = faiss.read_index(index_path)
            logging.info(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì„±ê³µ: {index_path}")
            return index
        except Exception as e:
            logging.error(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    else:
        logging.error(f"ì¸ë±ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {index_path}")
        return None

# í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± í•¨ìˆ˜ ì •ì˜
def embed_text(text):
    try:
        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)
        with torch.no_grad():
            embeddings = embedding_model(**inputs).last_hidden_state.mean(dim=1)
        return embeddings.squeeze().cpu().numpy()
    except Exception as e:
        logging.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# ì§ˆë¬¸ íŒŒì‹± í•¨ìˆ˜ ì •ì˜
def parse_question(question):
    """
    ì§ˆë¬¸ì„ íŒŒì‹±í•˜ì—¬ í•„í„°ë§ ê¸°ì¤€ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í˜„ì¬ëŠ” ìœ„ì¹˜ì™€ ì—°ë ¹ëŒ€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í•„ìš”ì— ë”°ë¼ ì¶”ê°€ì ì¸ í•„í„°ë§ ê¸°ì¤€ì„ ì¶”ì¶œí•˜ë„ë¡ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    location_match = re.search(r'ì œì£¼ì‹œ í•œë¦¼ì', question)
    age_group_match = re.search(r'(\d+)ëŒ€', question)
    
    location = location_match.group() if location_match else None
    age_group = age_group_match.group(1) if age_group_match else None
    
    return location, age_group

# Streamlit App UI ì„¤ì •
st.set_page_config(page_title="ğŸŠì œì£¼ë„ ë§›ì§‘ ì¶”ì²œ")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("**ğŸŠì œì£¼ë„ ë§›ì§‘ ì¶”ì²œ**")
    st.write("")
    st.markdown("""
        <style>
        .sidebar-text {
        color: #FFEC9D;
        font-size: 18px;
        font-weight: bold;
        }
     </style>
     """, unsafe_allow_html=True)
    st.sidebar.markdown('<p class="sidebar-text">ğŸ’µí¬ë§ ê°€ê²©ëŒ€ëŠ” ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”??</p>', unsafe_allow_html=True)

    price_options = ['ğŸ‘Œ ìƒê´€ ì—†ìŒ','ğŸ˜ ìµœê³ ê°€', 'ğŸ’¸ ê³ ê°€', 'ğŸ’° í‰ê·  ê°€ê²©ëŒ€', 'ğŸ’µ ì¤‘ì €ê°€', 'ğŸ˜‚ ì €ê°€']
    price_mapping = {
        'ğŸ‘Œ ìƒê´€ ì—†ìŒ': 'ìƒê´€ ì—†ìŒ',
        'ğŸ˜ ìµœê³ ê°€': 'ìµœê³ ê°€',
        'ğŸ’¸ ê³ ê°€': 'ê³ ê°€',
        'ğŸ’° í‰ê·  ê°€ê²©ëŒ€': 'í‰ê·  ê°€ê²©ëŒ€',
        'ğŸ’µ ì¤‘ì €ê°€': 'ì¤‘ì €ê°€',
        'ğŸ˜‚ ì €ê°€': 'ì €ê°€'
    }
    selected_price = st.sidebar.selectbox("", price_options, key="price")
    price = price_mapping.get(selected_price, 'ìƒê´€ ì—†ìŒ')

    st.markdown(
        """
         <style>
         [data-testid="stSidebar"] {
         background-color: #ff9900;
         }
         </style>
        """, unsafe_allow_html=True)
    st.write("")

st.title("ì–´ì„œ ì™€ìš©!ğŸ‘‹")
st.subheader("ì¸ê¸° ìˆëŠ” :orange[ì œì£¼ ë§›ì§‘]ğŸ½ï¸ğŸ˜ í›„íšŒëŠ” ì—†ì„ê±¸?!")

st.write("")
st.write("#í‘ë¼ì§€ #ì œì²  ìƒì„ íšŒ #í•´ë¬¼ë¼ë©´ #ìŠ¤í…Œì´í¬ #í•œì‹ #ì¤‘ì‹ #ì–‘ì‹ #ì¼ì‹ #í‘ë°±ìš”ë¦¬ì‚¬..ğŸ¤¤")

st.write("")

# ì´ë¯¸ì§€ ì¶”ê°€
image_path = "https://pimg.mk.co.kr/news/cms/202409/22/news-p.v1.20240922.a626061476c54127bbe4beb0aa12d050_P1.png"
image_html = f"""
<div style="display: flex; justify-content: center;">
    <img src="{image_path}" alt="centered image" width="70%">
</div>
"""
st.markdown(image_html, unsafe_allow_html=True)

st.write("")

# ëŒ€í™” ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì–´ë–¤ ì‹ë‹¹ ì°¾ìœ¼ì‹œë‚˜ìš”?? ìœ„ì¹˜, ì—…ì¢… ë“±ì„ ì•Œë ¤ì£¼ì‹œë©´ ìµœê³ ì˜ ë§›ì§‘ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!"}]

# ë©”ì‹œì§€ ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì±— ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
def clear_chat_history():
    st.session_state.messages = [{"role": "assistant", "content": "ì–´ë–¤ ì‹ë‹¹ ì°¾ìœ¼ì‹œë‚˜ìš”?? ìœ„ì¹˜, ì—…ì¢… ë“±ì„ ì•Œë ¤ì£¼ì‹œë©´ ìµœê³ ì˜ ë§›ì§‘ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!"}]
st.sidebar.button('ëŒ€í™” ì´ˆê¸°í™” ğŸ”„', on_click=clear_chat_history)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"
logging.info(f"ë””ë°”ì´ìŠ¤ ì„¤ì •: {device}")

# Hugging Face ì„ë² ë”© ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model_name = "jhgan/ko-sroberta-multitask"
tokenizer = AutoTokenizer.from_pretrained(model_name)
embedding_model = AutoModel.from_pretrained(model_name).to(device)
logging.info("ì„ë² ë”© ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ.")

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ
try:
    faiss_index = load_faiss_index(os.path.join(module_path, 'faiss_index_1.index'))
    if faiss_index is not None:
        logging.info("FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ.")
    else:
        st.error("FAISS ì¸ë±ìŠ¤ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        st.stop()
except FileNotFoundError as e:
    st.error(str(e))
    st.stop()
except Exception as e:
    st.error(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# FAISSë¥¼ í™œìš©í•œ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ì •ì˜
def generate_response_with_faiss(question, df, faiss_index, model, df_tour, k=3, print_prompt=True):
    location, age_group = parse_question(question)
    
    if not location:
        return "ì§ˆë¬¸ì—ì„œ ìœ„ì¹˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    # ìœ„ì¹˜ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
    filtered_df = df[df['ê°€ë§¹ì ì£¼ì†Œ'].str.contains(location)].copy()
    logging.info(f"ìœ„ì¹˜ í•„í„°ë§ ì™„ë£Œ: {location}, í•„í„°ë§ëœ ë°ì´í„° ìˆ˜: {len(filtered_df)}")
    
    # ê°€ê²©ëŒ€ í•„í„°ë§ ë¡œì§ ìˆ˜ì •
    if price != 'ìƒê´€ ì—†ìŒ':
        price_filter = {
            'ìµœê³ ê°€': '6',
            'ê³ ê°€': '5',
            'í‰ê·  ê°€ê²©ëŒ€': ('3', '4'),
            'ì¤‘ì €ê°€': '2',
            'ì €ê°€': '1'
        }
        if price in price_filter:
            if isinstance(price_filter[price], tuple):
                # startswith expects a tuple of strings
                filtered_df = filtered_df[filtered_df['ê±´ë‹¹í‰ê· ì´ìš©ê¸ˆì•¡êµ¬ê°„'].str.startswith(price_filter[price])].reset_index(drop=True)
            else:
                filtered_df = filtered_df[filtered_df['ê±´ë‹¹í‰ê· ì´ìš©ê¸ˆì•¡êµ¬ê°„'].str.startswith(price_filter[price])].reset_index(drop=True)
            logging.info(f"ê°€ê²©ëŒ€ í•„í„°ë§ ì™„ë£Œ: {price}, í•„í„°ë§ëœ ë°ì´í„° ìˆ˜: {len(filtered_df)}")
    
    if len(filtered_df) == 0:
        return "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # 'text' ì»¬ëŸ¼ í™•ì¸
    if 'text' not in filtered_df.columns:
        return "ë°ì´í„°ì…‹ì— 'text' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ì„ë² ë”© ìƒì„±
    query_embedding = embed_text(question)
    if query_embedding is None:
        return "ì§ˆë¬¸ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    query_embedding = query_embedding.reshape(1, -1).astype('float32')
    
    # FAISS ê²€ìƒ‰
    try:
        distances, indices = faiss_index.search(query_embedding, k)
        logging.info(f"FAISS ê²€ìƒ‰ ì™„ë£Œ: {k}ê°œ ê²°ê³¼")
    except Exception as e:
        logging.error(f"FAISS ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return "FAISS ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
    if indices.size == 0:
        return "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê²€ìƒ‰ëœ ì¹´í˜ë“¤ ì„ íƒ
    try:
        top_cafes = filtered_df.iloc[indices[0]].copy()
        logging.info(f"ê²€ìƒ‰ëœ ì¹´í˜ë“¤: {top_cafes['ê°€ë§¹ì ëª…'].tolist()}")
    except IndexError as e:
        logging.error(f"ì¸ë±ìŠ¤ ì´ˆê³¼ ì˜¤ë¥˜: {e}")
        return "ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê°€ì¥ ë†’ì€ 30ëŒ€ ì´ìš© ë¹„ì¤‘ì„ ê°€ì§„ ì¹´í˜ ì„ íƒ
    if not top_cafes.empty:
        top_cafe = top_cafes.loc[top_cafes['ìµœê·¼12ê°œì›”30ëŒ€íšŒì›ìˆ˜ë¹„ì¤‘'].idxmax()]
        reference_info = f"{top_cafe['ê°€ë§¹ì ëª…']} - {top_cafe['ê°€ë§¹ì ì£¼ì†Œ']} - 30ëŒ€ ë¹„ì¤‘: {top_cafe['ìµœê·¼12ê°œì›”30ëŒ€íšŒì›ìˆ˜ë¹„ì¤‘'] * 100:.1f}%"
        logging.info(f"ê°€ì¥ ë†’ì€ 30ëŒ€ ì´ìš© ë¹„ì¤‘ ì¹´í˜ ì„ íƒ: {top_cafe['ê°€ë§¹ì ëª…']}")
    else:
        reference_info = "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."
        logging.info("ê²€ìƒ‰ëœ ì¹´í˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê´€ê´‘ì§€ ì •ë³´ í•„í„°ë§ (í•„ìš” ì‹œ ìˆ˜ì • ê°€ëŠ¥)
    reference_tour = "\n".join(df_tour['text'].iloc[:1])  # ì˜ˆì‹œ: ì²« ë²ˆì§¸ ê´€ê´‘ì§€ ì •ë³´
    
    prompt = f"""ì§ˆë¬¸: {question}
ëŒ€ë‹µì‹œ í•„ìš”í•œ ë‚´ìš©: 
- ê·¼ì²˜ ìŒì‹ì ì„ ì¶”ì²œí• ë•ŒëŠ” ì§ˆë¬¸ì— ì£¼ì†Œì— ëŒ€í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ìŒì‹ì ì˜ ì£¼ì†Œê°€ ë¹„ìŠ·í•œì§€ í™•ì¸í•´.
- ì°¨ë¡œ ì´ë™ì‹œê°„ì´ ì–¼ë§ˆì¸ì§€ ì•Œë ¤ì¤˜. ì¶”ì²œí•´ì¤„ë•Œ ì´ë™ì‹œê°„ì„ ê³ ë ¤í•´ì„œ ë‹µë³€í•´ì¤˜.
- ê°€ë§¹ì ì—…ì¢…ì´ ì»¤í”¼ì¸ ê°€ê²ŒëŠ” ì—…ì¢…ì´ ì¹´í˜ì•¼.
- ëŒ€ë‹µí•´ì¤„ë•Œ ì—…ì¢…ë³„ë¡œ ê°€ëŠ¥í•˜ë©´ í•˜ë‚˜ì”© ì¶”ì²œí•´ì¤˜.
- ê·¸ë¦¬ê³  ì¶”ê°€ì ìœ¼ë¡œ ê·¸ ì¤‘ì—ì„œ ê°€ë§¹ì ê°œì ì¼ìê°€ ì˜¤ë˜ë˜ê³  ì´ìš©ê±´ìˆ˜ê°€ ë§ì€ ìŒì‹ì (ì˜¤ë˜ëœë§›ì§‘)ê³¼ ê°€ë§¹ì ê°œì ì¼ìê°€ ìµœê·¼ì´ê³  ì´ìš©ê±´ìˆ˜ê°€ ë§ì€ ìŒì‹ì (ìƒˆë¡œìš´ë§›ì§‘)ì„ ê°ê° ì¶”ì²œí•´ì¤¬ìœ¼ë©´ ì¢‹ê² ì–´.
ì°¸ê³ í•  ì •ë³´: {reference_info}
ì°¸ê³ í•  ê´€ê´‘ì§€ ì •ë³´: {reference_tour}
ì‘ë‹µ:"""
    
    if print_prompt:
        st.write('-----------------------------' * 3)
        st.write(prompt)
        st.write('-----------------------------' * 3)
    
    # ëª¨ë¸ ì‘ë‹µ ìƒì„±
    try:
        response = model.generate_content(prompt)
        logging.info("ëª¨ë¸ ì‘ë‹µ ìƒì„± ì™„ë£Œ.")
        return response.text if hasattr(response, 'text') else response
    except Exception as e:
        logging.error(f"ëª¨ë¸ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        return "ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±
if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            with st.spinner("ìƒê° ì¤‘..."):
                response = generate_response_with_faiss(prompt, df, faiss_index, model, df_tour, k=3)
                st.write(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
        
        # ë¡œê·¸ ê¸°ë¡
        logging.info(f"Question: {prompt}")
        logging.info(f"Answer: {response}")
