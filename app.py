import os
import numpy as np
import pandas as pd
from transformers import AutoTokenizer, AutoModel
import torch
import faiss
import streamlit as st
import google.generativeai as genai
import logging
import re

# ê²½ë¡œ ì„¤ì •
data_path = './data'
module_path = './modules'

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(filename='chatbot_logs.log', level=logging.INFO, 
                    format='%(asctime)s:%(levelname)s:%(message)s')

# Gemini ëª¨ë¸ ì„¤ì •
GOOGLE_API_KEY = st.secrets["import os
import numpy as np
import pandas as pd
from transformers import AutoTokenizer, AutoModel
import torch
import faiss
import streamlit as st
import google.generativeai as genai
import logging
import re

# ê²½ë¡œ ì„¤ì •
data_path = './data'
module_path = './modules'

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(filename='chatbot_logs.log', level=logging.INFO, 
                    format='%(asctime)s:%(levelname)s:%(message)s')

# Gemini ëª¨ë¸ ì„¤ì •
GOOGLE_API_KEY = st.secrets["API_KEY"]
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv(os.path.join(data_path, "JEJU_DATA.csv"), encoding='cp949')
df_tour = pd.read_csv(os.path.join(data_path, "JEJU_TOUR.csv"), encoding='cp949')
text_tour = df_tour['text'].tolist()

# ìµœì‹ ì—°ì›” ë°ì´í„°ë§Œ ì‚¬ìš©
df = df.loc[df.groupby('ê°€ë§¹ì ëª…')['ê¸°ì¤€ì—°ì›”'].idxmax()].reset_index(drop=True)

# Streamlit App UI

st.set_page_config(page_title="ğŸŠì œì£¼ë„ ë§›ì§‘ ì¶”ì²œ")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("**ğŸŠì œì£¼ë„ ë§›ì§‘ ì¶”ì²œ**")

    st.write("")
    st.markdown("""
        <style>
        .sidebar-text {
        color: #FFEC9D;
        font-size: 18px;
        font-weight: bold;
        }
     </style>
     """, unsafe_allow_html=True)

    st.sidebar.markdown('<p class="sidebar-text">ğŸ’µí¬ë§ ê°€ê²©ëŒ€ëŠ” ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”??</p>', unsafe_allow_html=True)

    price_options = ['ğŸ‘Œ ìƒê´€ ì—†ìŒ','ğŸ˜ ìµœê³ ê°€', 'ğŸ’¸ ê³ ê°€', 'ğŸ’° í‰ê·  ê°€ê²©ëŒ€', 'ğŸ’µ ì¤‘ì €ê°€', 'ğŸ˜‚ ì €ê°€']
    price_mapping = {
        'ğŸ‘Œ ìƒê´€ ì—†ìŒ': 'ìƒê´€ ì—†ìŒ',
        'ğŸ˜ ìµœê³ ê°€': 'ìµœê³ ê°€',
        'ğŸ’¸ ê³ ê°€': 'ê³ ê°€',
        'ğŸ’° í‰ê·  ê°€ê²©ëŒ€': 'í‰ê·  ê°€ê²©ëŒ€',
        'ğŸ’µ ì¤‘ì €ê°€': 'ì¤‘ì €ê°€',
        'ğŸ˜‚ ì €ê°€': 'ì €ê°€'
    }
    selected_price = st.sidebar.selectbox("", price_options, key="price")
    price = price_mapping.get(selected_price, 'ìƒê´€ ì—†ìŒ')

    st.markdown(
        """
         <style>
         [data-testid="stSidebar"] {
         background-color: #ff9900;
         }
         </style>
        """, unsafe_allow_html=True)
    st.write("")

st.title("ì–´ì„œ ì™€ìš©!ğŸ‘‹")
st.subheader("ì¸ê¸° ìˆëŠ” :orange[ì œì£¼ ë§›ì§‘]ğŸ½ï¸ğŸ˜ í›„íšŒëŠ” ì—†ì„ê±¸?!")

st.write("")
st.write("#í‘ë¼ì§€ #ì œì²  ìƒì„ íšŒ #í•´ë¬¼ë¼ë©´ #ìŠ¤í…Œì´í¬ #í•œì‹ #ì¤‘ì‹ #ì–‘ì‹ #ì¼ì‹ #í‘ë°±ìš”ë¦¬ì‚¬..ğŸ¤¤")

st.write("")

# ì´ë¯¸ì§€ ì¶”ê°€
image_path = "https://pimg.mk.co.kr/news/cms/202409/22/news-p.v1.20240922.a626061476c54127bbe4beb0aa12d050_P1.png"
image_html = f"""
<div style="display: flex; justify-content: center;">
    <img src="{image_path}" alt="centered image" width="70%">
</div>
"""
st.markdown(image_html, unsafe_allow_html=True)

st.write("")

# ëŒ€í™” ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì–´ë–¤ ì‹ë‹¹ ì°¾ìœ¼ì‹œë‚˜ìš”?? ìœ„ì¹˜, ì—…ì¢… ë“±ì„ ì•Œë ¤ì£¼ì‹œë©´ ìµœê³ ì˜ ë§›ì§‘ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!"}]

# ë©”ì‹œì§€ ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì±— ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
def clear_chat_history():
    st.session_state.messages = [{"role": "assistant", "content": "ì–´ë–¤ ì‹ë‹¹ ì°¾ìœ¼ì‹œë‚˜ìš”?? ìœ„ì¹˜, ì—…ì¢… ë“±ì„ ì•Œë ¤ì£¼ì‹œë©´ ìµœê³ ì˜ ë§›ì§‘ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!"}]
st.sidebar.button('ëŒ€í™” ì´ˆê¸°í™” ğŸ”„', on_click=clear_chat_history)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"

# Hugging Face ì„ë² ë”© ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model_name = "jhgan/ko-sroberta-multitask"
tokenizer = AutoTokenizer.from_pretrained(model_name)
embedding_model = AutoModel.from_pretrained(model_name).to(device)

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ í•¨ìˆ˜
def load_faiss_index(index_path=os.path.join(module_path, 'faiss_index_1.index')):
    if os.path.exists(index_path):
        index = faiss.read_index(index_path)
        return index
    else:
        raise FileNotFoundError(f"ì¸ë±ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {index_path}")

# í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
def embed_text(text):
    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)
    with torch.no_grad():
        embeddings = embedding_model(**inputs).last_hidden_state.mean(dim=1)
    return embeddings.squeeze().cpu().numpy()

# í…ìŠ¤íŠ¸ ì„ë² ë”© ë¡œë“œ
embeddings = np.load(os.path.join(module_path, 'embeddings_array_file_1.npy'))
embeddings_tour = np.load(os.path.join(module_path, 'embeddings_tour_array_file_1.npy'))

# ì§ˆë¬¸ íŒŒì‹± í•¨ìˆ˜
def parse_question(question):
    """
    ì§ˆë¬¸ì„ íŒŒì‹±í•˜ì—¬ í•„í„°ë§ ê¸°ì¤€ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í˜„ì¬ëŠ” ìœ„ì¹˜ì™€ ì—°ë ¹ëŒ€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í•„ìš”ì— ë”°ë¼ ì¶”ê°€ì ì¸ í•„í„°ë§ ê¸°ì¤€ì„ ì¶”ì¶œí•˜ë„ë¡ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    location_match = re.search(r'ì œì£¼ì‹œ í•œë¦¼ì', question)
    age_group_match = re.search(r'(\d+)ëŒ€', question)
    
    location = location_match.group() if location_match else None
    age_group = age_group_match.group(1) if age_group_match else None
    
    return location, age_group

# FAISSë¥¼ í™œìš©í•œ ì‘ë‹µ ìƒì„±
def generate_response_with_faiss(question, df, embeddings, model, df_tour, embeddings_tour, k=3, print_prompt=True):
    location, age_group = parse_question(question)
    
    if not location:
        return "ì§ˆë¬¸ì—ì„œ ìœ„ì¹˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    # ìœ„ì¹˜ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
    filtered_df = df[df['ê°€ë§¹ì ì£¼ì†Œ'].str.contains(location)].copy()
    
    # ê°€ê²©ëŒ€ í•„í„°ë§ ë¡œì§ ìˆ˜ì •
    if price != 'ìƒê´€ ì—†ìŒ':
        price_filter = {
            'ìµœê³ ê°€': '6',
            'ê³ ê°€': '5',
            'í‰ê·  ê°€ê²©ëŒ€': ('3', '4'),
            'ì¤‘ì €ê°€': '2',
            'ì €ê°€': '1'
        }
        if price in price_filter:
            if isinstance(price_filter[price], tuple):
                # startswith expects a single string or tuple of strings
                filtered_df = filtered_df[filtered_df['ê±´ë‹¹í‰ê· ì´ìš©ê¸ˆì•¡êµ¬ê°„'].str.startswith(price_filter[price])].reset_index(drop=True)
            else:
                filtered_df = filtered_df[filtered_df['ê±´ë‹¹í‰ê· ì´ìš©ê¸ˆì•¡êµ¬ê°„'].str.startswith(price_filter[price])].reset_index(drop=True)
    
    # FAISS ì¸ë±ìŠ¤ ì¬êµ¬ì„± (í•„í„°ë§ëœ ë°ì´í„°ë¡œ)
    if len(filtered_df) == 0:
        return "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
    if 'text' not in filtered_df.columns:
        return "ë°ì´í„°ì…‹ì— 'text' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ì„ë² ë”© ìƒì„± (í•„í„°ë§ëœ ë°ì´í„°)
    filtered_embeddings = np.array([embed_text(text) for text in filtered_df['text']])
    
    # FAISS ì¸ë±ìŠ¤ ìƒì„±
    dimension = filtered_embeddings.shape[1]
    faiss_index = faiss.IndexFlatL2(dimension)
    faiss_index.add(filtered_embeddings)
    
    # FAISS ê²€ìƒ‰
    query_embedding = embed_text(question).reshape(1, -1)
    distances, indices = faiss_index.search(query_embedding, k)
    
    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
    if indices.size == 0:
        return "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê²€ìƒ‰ëœ ì¹´í˜ë“¤ ì„ íƒ
    top_cafes = filtered_df.iloc[indices[0, :]].copy()
    
    # ê°€ì¥ ë†’ì€ 30ëŒ€ ì´ìš© ë¹„ì¤‘ì„ ê°€ì§„ ì¹´í˜ ì„ íƒ
    if not top_cafes.empty:
        top_cafe = top_cafes.loc[top_cafes['ìµœê·¼12ê°œì›”30ëŒ€íšŒì›ìˆ˜ë¹„ì¤‘'].idxmax()]
        reference_info = f"{top_cafe['ê°€ë§¹ì ëª…']} - {top_cafe['ê°€ë§¹ì ì£¼ì†Œ']} - 30ëŒ€ ë¹„ì¤‘: {top_cafe['ìµœê·¼12ê°œì›”30ëŒ€íšŒì›ìˆ˜ë¹„ì¤‘'] * 100:.1f}%"
    else:
        reference_info = "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê´€ê´‘ì§€ ì •ë³´ í•„í„°ë§ (í•„ìš” ì‹œ ìˆ˜ì • ê°€ëŠ¥)
    reference_tour = "\n".join(df_tour['text'].iloc[:1])  # ì˜ˆì‹œ: ì²« ë²ˆì§¸ ê´€ê´‘ì§€ ì •ë³´
    
    prompt = f"""ì§ˆë¬¸: {question}
ëŒ€ë‹µì‹œ í•„ìš”í•œ ë‚´ìš©: 
- ê·¼ì²˜ ìŒì‹ì ì„ ì¶”ì²œí• ë•ŒëŠ” ì§ˆë¬¸ì— ì£¼ì†Œì— ëŒ€í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ìŒì‹ì ì˜ ì£¼ì†Œê°€ ë¹„ìŠ·í•œì§€ í™•ì¸í•´.
- ì°¨ë¡œ ì´ë™ì‹œê°„ì´ ì–¼ë§ˆì¸ì§€ ì•Œë ¤ì¤˜. ì¶”ì²œí•´ì¤„ë•Œ ì´ë™ì‹œê°„ì„ ê³ ë ¤í•´ì„œ ë‹µë³€í•´ì¤˜.
- ê°€ë§¹ì ì—…ì¢…ì´ ì»¤í”¼ì¸ ê°€ê²ŒëŠ” ì—…ì¢…ì´ ì¹´í˜ì•¼.
- ëŒ€ë‹µí•´ì¤„ë•Œ ì—…ì¢…ë³„ë¡œ ê°€ëŠ¥í•˜ë©´ í•˜ë‚˜ì”© ì¶”ì²œí•´ì¤˜.
- ê·¸ë¦¬ê³  ì¶”ê°€ì ìœ¼ë¡œ ê·¸ ì¤‘ì—ì„œ ê°€ë§¹ì ê°œì ì¼ìê°€ ì˜¤ë˜ë˜ê³  ì´ìš©ê±´ìˆ˜ê°€ ë§ì€ ìŒì‹ì (ì˜¤ë˜ëœë§›ì§‘)ê³¼ ê°€ë§¹ì ê°œì ì¼ìê°€ ìµœê·¼ì´ê³  ì´ìš©ê±´ìˆ˜ê°€ ë§ì€ ìŒì‹ì (ìƒˆë¡œìš´ë§›ì§‘)ì„ ê°ê° ì¶”ì²œí•´ì¤¬ìœ¼ë©´ ì¢‹ê² ì–´.
ì°¸ê³ í•  ì •ë³´: {reference_info}
ì°¸ê³ í•  ê´€ê´‘ì§€ ì •ë³´: {reference_tour}
ì‘ë‹µ:"""
    
    if print_prompt:
        print('-----------------------------' * 3)
        print(prompt)
        print('-----------------------------' * 3)
    
    response = model.generate_content(prompt)
    return response.text if hasattr(response, 'text') else response

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±
if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            with st.spinner("ìƒê° ì¤‘..."):
                response = generate_response_with_faiss(prompt, df, embeddings, model, df_tour, embeddings_tour)
                st.write(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
        
        # ë¡œê·¸ ê¸°ë¡
        logging.info(f"Question: {prompt}")
        logging.info(f"Answer: {response}")

# í”¼ë“œë°± í¼ ì¶”ê°€
def get_feedback():
    st.sidebar.header("ğŸ’¬ í”¼ë“œë°±")
    feedback = st.sidebar.text_area("ì¶”ì²œì— ëŒ€í•œ í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”.")
    if st.sidebar.button("ì œì¶œ"):
        if feedback:
            with open("feedback.log", "a", encoding="utf-8") as f:
                f.write(f"Feedback: {feedback}\n")
            st.sidebar.success("í”¼ë“œë°±ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
        else:
            st.sidebar.warning("í”¼ë“œë°±ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# í”¼ë“œë°± í¼ í˜¸ì¶œ
get_feedback()
"]
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv(os.path.join(data_path, "JEJU_DATA.csv"), encoding='cp949')
df_tour = pd.read_csv(os.path.join(data_path, "JEJU_TOUR.csv"), encoding='cp949')
text_tour = df_tour['text'].tolist()

# ìµœì‹ ì—°ì›” ë°ì´í„°ë§Œ ì‚¬ìš©
df = df.loc[df.groupby('ê°€ë§¹ì ëª…')['ê¸°ì¤€ì—°ì›”'].idxmax()].reset_index(drop=True)

# Streamlit App UI

st.set_page_config(page_title="ğŸŠì œì£¼ë„ ë§›ì§‘ ì¶”ì²œ")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("**ğŸŠì œì£¼ë„ ë§›ì§‘ ì¶”ì²œ**")

    st.write("")
    st.markdown("""
        <style>
        .sidebar-text {
        color: #FFEC9D;
        font-size: 18px;
        font-weight: bold;
        }
     </style>
     """, unsafe_allow_html=True)

    st.sidebar.markdown('<p class="sidebar-text">ğŸ’µí¬ë§ ê°€ê²©ëŒ€ëŠ” ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”??</p>', unsafe_allow_html=True)

    price_options = ['ğŸ‘Œ ìƒê´€ ì—†ìŒ','ğŸ˜ ìµœê³ ê°€', 'ğŸ’¸ ê³ ê°€', 'ğŸ’° í‰ê·  ê°€ê²©ëŒ€', 'ğŸ’µ ì¤‘ì €ê°€', 'ğŸ˜‚ ì €ê°€']
    price_mapping = {
        'ğŸ‘Œ ìƒê´€ ì—†ìŒ': 'ìƒê´€ ì—†ìŒ',
        'ğŸ˜ ìµœê³ ê°€': 'ìµœê³ ê°€',
        'ğŸ’¸ ê³ ê°€': 'ê³ ê°€',
        'ğŸ’° í‰ê·  ê°€ê²©ëŒ€': 'í‰ê·  ê°€ê²©ëŒ€',
        'ğŸ’µ ì¤‘ì €ê°€': 'ì¤‘ì €ê°€',
        'ğŸ˜‚ ì €ê°€': 'ì €ê°€'
    }
    selected_price = st.sidebar.selectbox("", price_options, key="price")
    price = price_mapping.get(selected_price, 'ìƒê´€ ì—†ìŒ')

    st.markdown(
        """
         <style>
         [data-testid="stSidebar"] {
         background-color: #ff9900;
         }
         </style>
        """, unsafe_allow_html=True)
    st.write("")

st.title("ì–´ì„œ ì™€ìš©!ğŸ‘‹")
st.subheader("ì¸ê¸° ìˆëŠ” :orange[ì œì£¼ ë§›ì§‘]ğŸ½ï¸ğŸ˜ í›„íšŒëŠ” ì—†ì„ê±¸?!")

st.write("")
st.write("#í‘ë¼ì§€ #ì œì²  ìƒì„ íšŒ #í•´ë¬¼ë¼ë©´ #ìŠ¤í…Œì´í¬ #í•œì‹ #ì¤‘ì‹ #ì–‘ì‹ #ì¼ì‹ #í‘ë°±ìš”ë¦¬ì‚¬..ğŸ¤¤")

st.write("")

# ì´ë¯¸ì§€ ì¶”ê°€
image_path = "https://pimg.mk.co.kr/news/cms/202409/22/news-p.v1.20240922.a626061476c54127bbe4beb0aa12d050_P1.png"
image_html = f"""
<div style="display: flex; justify-content: center;">
    <img src="{image_path}" alt="centered image" width="70%">
</div>
"""
st.markdown(image_html, unsafe_allow_html=True)

st.write("")

# ëŒ€í™” ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì–´ë–¤ ì‹ë‹¹ ì°¾ìœ¼ì‹œë‚˜ìš”?? ìœ„ì¹˜, ì—…ì¢… ë“±ì„ ì•Œë ¤ì£¼ì‹œë©´ ìµœê³ ì˜ ë§›ì§‘ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!"}]

# ë©”ì‹œì§€ ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì±— ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
def clear_chat_history():
    st.session_state.messages = [{"role": "assistant", "content": "ì–´ë–¤ ì‹ë‹¹ ì°¾ìœ¼ì‹œë‚˜ìš”?? ìœ„ì¹˜, ì—…ì¢… ë“±ì„ ì•Œë ¤ì£¼ì‹œë©´ ìµœê³ ì˜ ë§›ì§‘ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!"}]
st.sidebar.button('ëŒ€í™” ì´ˆê¸°í™” ğŸ”„', on_click=clear_chat_history)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"

# Hugging Face ì„ë² ë”© ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model_name = "jhgan/ko-sroberta-multitask"
tokenizer = AutoTokenizer.from_pretrained(model_name)
embedding_model = AutoModel.from_pretrained(model_name).to(device)

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ í•¨ìˆ˜
def load_faiss_index(index_path=os.path.join(module_path, 'faiss_index_1.index')):
    if os.path.exists(index_path):
        index = faiss.read_index(index_path)
        return index
    else:
        raise FileNotFoundError(f"ì¸ë±ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {index_path}")

# í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
def embed_text(text):
    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)
    with torch.no_grad():
        embeddings = embedding_model(**inputs).last_hidden_state.mean(dim=1)
    return embeddings.squeeze().cpu().numpy()

# í…ìŠ¤íŠ¸ ì„ë² ë”© ë¡œë“œ
embeddings = np.load(os.path.join(module_path, 'embeddings_array_file_1.npy'))
embeddings_tour = np.load(os.path.join(module_path, 'embeddings_tour_array_file_1.npy'))

# ì§ˆë¬¸ íŒŒì‹± í•¨ìˆ˜
def parse_question(question):
    """
    ì§ˆë¬¸ì„ íŒŒì‹±í•˜ì—¬ í•„í„°ë§ ê¸°ì¤€ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í˜„ì¬ëŠ” ìœ„ì¹˜ì™€ ì—°ë ¹ëŒ€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í•„ìš”ì— ë”°ë¼ ì¶”ê°€ì ì¸ í•„í„°ë§ ê¸°ì¤€ì„ ì¶”ì¶œí•˜ë„ë¡ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    location_match = re.search(r'ì œì£¼ì‹œ í•œë¦¼ì', question)
    age_group_match = re.search(r'(\d+)ëŒ€', question)
    
    location = location_match.group() if location_match else None
    age_group = age_group_match.group(1) if age_group_match else None
    
    return location, age_group

# FAISSë¥¼ í™œìš©í•œ ì‘ë‹µ ìƒì„±
def generate_response_with_faiss(question, df, embeddings, model, df_tour, embeddings_tour, k=3, print_prompt=True):
    location, age_group = parse_question(question)
    
    if not location:
        return "ì§ˆë¬¸ì—ì„œ ìœ„ì¹˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    # ìœ„ì¹˜ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
    filtered_df = df[df['ê°€ë§¹ì ì£¼ì†Œ'].str.contains(location)].copy()
    
    # ê°€ê²©ëŒ€ í•„í„°ë§ ë¡œì§ ìˆ˜ì •
    if price != 'ìƒê´€ ì—†ìŒ':
        price_filter = {
            'ìµœê³ ê°€': '6',
            'ê³ ê°€': '5',
            'í‰ê·  ê°€ê²©ëŒ€': ('3', '4'),
            'ì¤‘ì €ê°€': '2',
            'ì €ê°€': '1'
        }
        if price in price_filter:
            if isinstance(price_filter[price], tuple):
                # startswith expects a single string or tuple of strings
                filtered_df = filtered_df[filtered_df['ê±´ë‹¹í‰ê· ì´ìš©ê¸ˆì•¡êµ¬ê°„'].str.startswith(price_filter[price])].reset_index(drop=True)
            else:
                filtered_df = filtered_df[filtered_df['ê±´ë‹¹í‰ê· ì´ìš©ê¸ˆì•¡êµ¬ê°„'].str.startswith(price_filter[price])].reset_index(drop=True)
    
    # FAISS ì¸ë±ìŠ¤ ì¬êµ¬ì„± (í•„í„°ë§ëœ ë°ì´í„°ë¡œ)
    if len(filtered_df) == 0:
        return "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
    if 'text' not in filtered_df.columns:
        return "ë°ì´í„°ì…‹ì— 'text' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ì„ë² ë”© ìƒì„± (í•„í„°ë§ëœ ë°ì´í„°)
    filtered_embeddings = np.array([embed_text(text) for text in filtered_df['text']])
    
    # FAISS ì¸ë±ìŠ¤ ìƒì„±
    dimension = filtered_embeddings.shape[1]
    faiss_index = faiss.IndexFlatL2(dimension)
    faiss_index.add(filtered_embeddings)
    
    # FAISS ê²€ìƒ‰
    query_embedding = embed_text(question).reshape(1, -1)
    distances, indices = faiss_index.search(query_embedding, k)
    
    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
    if indices.size == 0:
        return "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê²€ìƒ‰ëœ ì¹´í˜ë“¤ ì„ íƒ
    top_cafes = filtered_df.iloc[indices[0, :]].copy()
    
    # ê°€ì¥ ë†’ì€ 30ëŒ€ ì´ìš© ë¹„ì¤‘ì„ ê°€ì§„ ì¹´í˜ ì„ íƒ
    if not top_cafes.empty:
        top_cafe = top_cafes.loc[top_cafes['ìµœê·¼12ê°œì›”30ëŒ€íšŒì›ìˆ˜ë¹„ì¤‘'].idxmax()]
        reference_info = f"{top_cafe['ê°€ë§¹ì ëª…']} - {top_cafe['ê°€ë§¹ì ì£¼ì†Œ']} - 30ëŒ€ ë¹„ì¤‘: {top_cafe['ìµœê·¼12ê°œì›”30ëŒ€íšŒì›ìˆ˜ë¹„ì¤‘'] * 100:.1f}%"
    else:
        reference_info = "ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê´€ê´‘ì§€ ì •ë³´ í•„í„°ë§ (í•„ìš” ì‹œ ìˆ˜ì • ê°€ëŠ¥)
    reference_tour = "\n".join(df_tour['text'].iloc[:1])  # ì˜ˆì‹œ: ì²« ë²ˆì§¸ ê´€ê´‘ì§€ ì •ë³´
    
    prompt = f"""ì§ˆë¬¸: {question}
ëŒ€ë‹µì‹œ í•„ìš”í•œ ë‚´ìš©: 
- ê·¼ì²˜ ìŒì‹ì ì„ ì¶”ì²œí• ë•ŒëŠ” ì§ˆë¬¸ì— ì£¼ì†Œì— ëŒ€í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ìŒì‹ì ì˜ ì£¼ì†Œê°€ ë¹„ìŠ·í•œì§€ í™•ì¸í•´.
- ì°¨ë¡œ ì´ë™ì‹œê°„ì´ ì–¼ë§ˆì¸ì§€ ì•Œë ¤ì¤˜. ì¶”ì²œí•´ì¤„ë•Œ ì´ë™ì‹œê°„ì„ ê³ ë ¤í•´ì„œ ë‹µë³€í•´ì¤˜.
- ê°€ë§¹ì ì—…ì¢…ì´ ì»¤í”¼ì¸ ê°€ê²ŒëŠ” ì—…ì¢…ì´ ì¹´í˜ì•¼.
- ëŒ€ë‹µí•´ì¤„ë•Œ ì—…ì¢…ë³„ë¡œ ê°€ëŠ¥í•˜ë©´ í•˜ë‚˜ì”© ì¶”ì²œí•´ì¤˜.
- ê·¸ë¦¬ê³  ì¶”ê°€ì ìœ¼ë¡œ ê·¸ ì¤‘ì—ì„œ ê°€ë§¹ì ê°œì ì¼ìê°€ ì˜¤ë˜ë˜ê³  ì´ìš©ê±´ìˆ˜ê°€ ë§ì€ ìŒì‹ì (ì˜¤ë˜ëœë§›ì§‘)ê³¼ ê°€ë§¹ì ê°œì ì¼ìê°€ ìµœê·¼ì´ê³  ì´ìš©ê±´ìˆ˜ê°€ ë§ì€ ìŒì‹ì (ìƒˆë¡œìš´ë§›ì§‘)ì„ ê°ê° ì¶”ì²œí•´ì¤¬ìœ¼ë©´ ì¢‹ê² ì–´.
ì°¸ê³ í•  ì •ë³´: {reference_info}
ì°¸ê³ í•  ê´€ê´‘ì§€ ì •ë³´: {reference_tour}
ì‘ë‹µ:"""
    
    if print_prompt:
        print('-----------------------------' * 3)
        print(prompt)
        print('-----------------------------' * 3)
    
    response = model.generate_content(prompt)
    return response.text if hasattr(response, 'text') else response

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±
if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            with st.spinner("ìƒê° ì¤‘..."):
                response = generate_response_with_faiss(prompt, df, embeddings, model, df_tour, embeddings_tour)
                st.write(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
        
        # ë¡œê·¸ ê¸°ë¡
        logging.info(f"Question: {prompt}")
        logging.info(f"Answer: {response}")

# í”¼ë“œë°± í¼ ì¶”ê°€
def get_feedback():
    st.sidebar.header("ğŸ’¬ í”¼ë“œë°±")
    feedback = st.sidebar.text_area("ì¶”ì²œì— ëŒ€í•œ í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”.")
    if st.sidebar.button("ì œì¶œ"):
        if feedback:
            with open("feedback.log", "a", encoding="utf-8") as f:
                f.write(f"Feedback: {feedback}\n")
            st.sidebar.success("í”¼ë“œë°±ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
        else:
            st.sidebar.warning("í”¼ë“œë°±ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# í”¼ë“œë°± í¼ í˜¸ì¶œ
get_feedback()
